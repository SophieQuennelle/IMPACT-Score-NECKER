{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active larning labelling to create train and dev sets for the text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import pathlib\n",
    "import os \n",
    "import shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import itertools\n",
    "import shutil\n",
    "from sklearn import preprocessing\n",
    "from  sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Create files and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "shutil.rmtree(\"train\", ignore_errors=True)\n",
    "\n",
    "shutil.rmtree(\"test\", ignore_errors=True)\n",
    "\n",
    "shutil.rmtree(\"unlabeled\", ignore_errors=True)\n",
    "\n",
    "shutil.rmtree(\"all_clac\", ignore_errors=True)\n",
    "\n",
    "shutil.rmtree(\"all_pas_clac\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clac is the name we gave to sequences of texte referring to a major adverse event (positive)\n",
    "# pas_clac are sequences that do not refer to a major adverse event (negative sample).\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "path = \"train/pas_clac\"\n",
    "os.makedirs(path)\n",
    "\n",
    "path = \"test/clac\"\n",
    "os.makedirs(path)\n",
    "\n",
    "path = \"test/pas_clac\"\n",
    "os.makedirs(path)\n",
    "\n",
    "path = \"train/clac\"\n",
    "os.makedirs(path)\n",
    "\n",
    "path = \"unlabeled/unlabeled\"\n",
    "os.makedirs(path)\n",
    "\n",
    "# all_clac and all_pas_clac will be used to shuffle samples.\n",
    "\n",
    "path_all_clac = \"./all_clac\"\n",
    "os.makedirs(path_all_clac)\n",
    "\n",
    "path_all_pas_clac = \"./all_pas_clac\"\n",
    "os.makedirs(path_all_pas_clac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text sequence to annotate\n",
    "\n",
    "extraction_tc = pd.read_excel('extraction_tc.xlsx')\n",
    "\n",
    "df_extraction_tc = pd.DataFrame(extraction_tc)\n",
    "\n",
    "df_stacked1 = df_extraction_tc.set_index(['IPP', 'DDK']).stack()\n",
    "\n",
    "extraction_tc2 = pd.read_excel('extraction_tc2.xlsx')\n",
    "\n",
    "df_extraction_tc2 = pd.DataFrame(extraction_tc2)\n",
    "\n",
    "df_stacked2 = df_extraction_tc2.set_index(['IPP', 'DDK']).stack()\n",
    "\n",
    "extraction_tc3 = pd.read_excel('extraction_tc3.xlsx')\n",
    "\n",
    "df_extraction_tc3 = pd.DataFrame(extraction_tc3)\n",
    "\n",
    "df_stacked3 = df_extraction_tc3.set_index(['IPP', 'DDK']).stack()\n",
    "\n",
    "df_stacked = pd.concat([df_stacked1, df_stacked2, df_stacked3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correspondence table (between sequence and patient ID).\n",
    "\n",
    "df_stacked = df_stacked.reset_index()\n",
    "\n",
    "df_stacked.rename(columns={0:'texte_complication', 'level_2':'type_complication'}, inplace=True)\n",
    "\n",
    "df_stacked.to_excel('table_de_correspondance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texte preprocessing\n",
    "\n",
    "noise_list = [\",\", \".\", \"?\", \";\", \":\", \"/\", \"!\", \"-\", \"+\", \"ÿ\", \"à\"] \n",
    "word_noise_list = [\"a\", \"ainsi\", \"assez\", \"au\", \"aux\", \"ce\", \"ceci\", \"cela\",\n",
    "                   \"car\", \"ces\", \"cette\", \"ce\", \"celle\", \"du\", \"en\", \"il\", \"ils\"\n",
    "                   \"elle\", \"elles\", \"que\", \"qui\", \"qu'\", \"se\", \"son\", \"sa\", \"ses\",\n",
    "                   \"le\", \"la\", \"les\", \"l'\", \"un\", \"une\", \"de\", \"des\", \"au\", \"du\"]\n",
    "\n",
    "\n",
    "def remove_noise(input_text):\n",
    "    noise_free_words = [caracter for caracter in input_text.lower() if caracter not in noise_list]\n",
    "    noise_free_text = \"\".join(noise_free_words) \n",
    "    word_list = [word for word in noise_free_text.split(\" \") if word not in word_noise_list]\n",
    "    ouput_text = \" \".join(word_list)\n",
    "    return ouput_text\n",
    "\n",
    "df_stacked['texte_complication'] = df_stacked['texte_complication'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To remove samples that are already in the dev, test or train set\n",
    "\n",
    "dev_id_list = list(pd.read_excel(\"dev_unlabeled.xlsx\", index_col=0).index)\n",
    "\n",
    "labeled_files = []\n",
    "for directory in ['train/clac', 'train/pas_clac', 'test/clac', 'test/pas_clac' ]:\n",
    "    labeled_files += [int(f[:-4]) for f in listdir(directory) if f != 'desktop.ini' if isfile(join(directory, f))]\n",
    "print(labeled_files)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To remove from df_stacked samples that are already labeled or that are in the dev set\n",
    "\n",
    "all_indices_to_removes = dev_id_list + labeled_files\n",
    "\n",
    "indices_to_keep = df_stacked.index.difference(all_indices_to_removes)\n",
    "df_stacked = df_stacked.loc[indices_to_keep]\n",
    "df_stacked.to_excel('df_stacked.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a representative devset to be annotated without active learning\n",
    "\n",
    "# Select 10% of the samples at random\n",
    "df_stacked\n",
    "index = df_stacked.index\n",
    "number_of_rows = len(index)\n",
    "x = number_of_rows // 10\n",
    "print(\"Il faut mettre de coté :\", x, \"exemples.\")\n",
    "\n",
    "df_dev = df_stacked.sample(n=x, random_state=1)\n",
    "df_dev.to_excel(\"dev_unlabeled.xlsx\") \n",
    "\n",
    "# Other samples\n",
    "df_model = pd.concat([df_stacked, df_dev]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files .csv with samples in it and nammed after correspondence table index\n",
    "\n",
    "directory = pathlib.Path().absolute()\n",
    "DATA_FOLDER = directory\n",
    "TRAIN_FOLDER = os.path.join(DATA_FOLDER, \"train\")\n",
    "TEST_FOLDER = os.path.join(DATA_FOLDER, \"test\")\n",
    "UNLABELED_FOLDER = os.path.join(DATA_FOLDER, \"unlabeled\")\n",
    "ENCODING = 'utf-8'\n",
    "categories = ['clac', 'pas_clac']\n",
    "\n",
    "for idx, row_data in df_stacked.iterrows():\n",
    "    file_name = os.path.join(UNLABELED_FOLDER, 'unlabeled')\n",
    "    file_name = os.path.join(os.path.join(file_name), str(idx) + '.txt')\n",
    "       \n",
    "    create_file = open(file_name, \"w+\", encoding='utf-8')\n",
    "    create_file.write(row_data['texte_complication'])\n",
    "    create_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Labelling at random (300 samples to begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 300\n",
    "\n",
    "\n",
    "for row in df_model.sample(s).iterrows():\n",
    "    file_name = os.path.join(UNLABELED_FOLDER, 'unlabeled')\n",
    "    file_name = os.path.join(os.path.join(file_name), str(row[0]) + '.txt')\n",
    "    print(row[1]['texte_complication'])\n",
    "    labelNumber = input(\"Enter the correct label number: 1 = CLAC OU 2 = pas une CLAC :\")\n",
    "    while labelNumber.isdigit()== False:\n",
    "        labelNumber = input(\"Enter the correct label number\")\n",
    "    labelNumber = int(labelNumber)\n",
    "    category = categories[labelNumber - 1]\n",
    "    if np.random.rand() < .3:\n",
    "        dstDir = os.path.join(TEST_FOLDER, category)         \n",
    "    else:\n",
    "        dstDir = os.path.join(TRAIN_FOLDER, category) \n",
    "    print(dstDir)\n",
    "    print(file_name)\n",
    "    shutil.move(file_name, dstDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Active labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions definition\n",
    "\n",
    "# File size of the dataset\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "# Fit terminal size\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, X_train, X_test, y_train, y_test, X_unlabeled):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "\n",
    "    # Create a scaler fitted to X_train to later standarize all the subsets with the same scale\n",
    "    scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "    scaler = scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)  # Standardizing     \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    X_test = scaler.transform(X_test) # Standardizing\n",
    "    pred = clf.predict(X_test) \n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.f1_score(y_test, pred)\n",
    "    accscore = metrics.accuracy_score(y_test, pred)\n",
    "    print (\"pred count is %d\" %len(pred))\n",
    "    print ('accuracy score:     %0.3f' % accscore)\n",
    "    print(\"f1-score:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=categories))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    print(\"tn :\", tn, \"fp :\", fp, \"fn :\", fn, \"tp :\", tp)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                      (\"Normalized confusion matrix\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                             display_labels=categories,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"confidence for unlabeled data:\")\n",
    "\n",
    "    X_unlabeled = scaler.transform(X_unlabeled) # Standardizing ------------------\n",
    "\n",
    "    # compute absolute confidence for each unlabeled sample in each class\n",
    "    ## To suggest negative samples (i.e. more likely to be major adverse event)\n",
    "    question_samples = []\n",
    "    confidences = - clf.decision_function(X_unlabeled)\n",
    "    sorted_confidences = np.argsort(confidences)\n",
    "    high_confidence_samples = sorted_confidences[-NUM_QUESTIONS:]\n",
    "    question_samples.extend(high_confidence_samples.tolist())\n",
    "\n",
    "    ## OR to suggest samples closest to the line (hardest to classify)\n",
    "    confidences = np.abs(clf.decision_function(X_unlabeled))\n",
    "    sorted_confidences = np.argsort(confidences)\n",
    "    low_confidence_samples = sorted_confidences[0:NUM_QUESTIONS]\n",
    "    question_samples.extend(low_confidence_samples.tolist())\n",
    "    \n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time, question_samples\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "NUM_QUESTIONS = 2\n",
    "PLOT_RESULTS = True\n",
    "ACTIVE = True\n",
    "directory = pathlib.Path().absolute()\n",
    "DATA_FOLDER = directory\n",
    "TRAIN_FOLDER = os.path.join(DATA_FOLDER, \"train\")\n",
    "TEST_FOLDER = os.path.join(DATA_FOLDER, \"test\")\n",
    "UNLABELED_FOLDER = os.path.join(DATA_FOLDER, \"unlabeled\")\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "while True:\n",
    "    data_train = load_files(TRAIN_FOLDER, encoding=ENCODING)\n",
    "    data_test = load_files(TEST_FOLDER, encoding=ENCODING)\n",
    "    data_unlabeled = load_files(UNLABELED_FOLDER, encoding=ENCODING)\n",
    "    categories = data_train.target_names\n",
    "    \n",
    "    data_train_size_mb = size_mb(data_train.data)\n",
    "    data_test_size_mb = size_mb(data_test.data)\n",
    "    data_unlabeled_size_mb = size_mb(data_unlabeled.data)\n",
    "    \n",
    "    print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "        len(data_train.data), data_train_size_mb))\n",
    "    print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "        len(data_test.data), data_test_size_mb))\n",
    "    print(\"%d documents - %0.3fMB (unlabeled set)\" % (\n",
    "        len(data_unlabeled.data), data_unlabeled_size_mb))\n",
    "    print(\"%d categories\" % len(categories))\n",
    "    print()\n",
    "    y_train = data_train.target\n",
    "    y_test =  data_test.target\n",
    "    \n",
    "    print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "    t0 = time()\n",
    "    vectorizer = TfidfVectorizer(encoding= ENCODING, use_idf=True, norm='l1', binary=False, sublinear_tf=True, min_df=0.001, max_df=1.0, ngram_range=(1, 2), analyzer='word', stop_words=None)\n",
    "    \n",
    "    # the output of the fit_transform (x_train) is a sparse csc matrix.\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    duration = time() - t0\n",
    "    # print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    print()\n",
    "    \n",
    "    print(\"Extracting features from the test dataset using the same vectorizer\")\n",
    "    t0 = time()\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    duration = time() - t0\n",
    "    # print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "    print()\n",
    "    \n",
    "    print(\"Extracting features from the unlabled dataset using the same vectorizer\")\n",
    "    t0 = time()\n",
    "    X_unlabeled = vectorizer.transform(data_unlabeled.data)\n",
    "    duration = time() - t0\n",
    "    # print(\"done in %fs at %0.3fMB/s\" % (duration, data_unlabeled_size_mb / duration))\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_unlabeled.shape)\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty='l2', \n",
    "                                                dual=False, tol=1e-3, class_weight='balanced'), \n",
    "                                                 X_train, X_test, y_train, y_test, X_unlabeled))\n",
    "    \n",
    "    # make some plots\n",
    "    indices = np.arange(len(results))\n",
    "    results = [[x[i] for x in results] for i in range(5)]\n",
    "    \n",
    "    clf_names, score, training_time, test_time, question_samples = results\n",
    "    training_time = np.array(training_time) / np.max(training_time)\n",
    "    test_time = np.array(test_time) / np.max(test_time)\n",
    "    \n",
    "    if PLOT_RESULTS:\n",
    "        pl.figure(figsize=(12,8))\n",
    "        pl.title(\"Score\")\n",
    "        pl.barh(indices, score, .2, label=\"score\", color='r')\n",
    "        pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
    "        pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
    "        pl.yticks(())\n",
    "        pl.legend(loc='best')\n",
    "        pl.subplots_adjust(left=.25)\n",
    "        pl.subplots_adjust(top=.95)\n",
    "        pl.subplots_adjust(bottom=.05)\n",
    "        \n",
    "        for i, c in zip(indices, clf_names):\n",
    "            pl.text(-.3, i, c)\n",
    "        pl.savefig('ngramoptimize.png')\n",
    "        pl.show()\n",
    "\n",
    "    if ACTIVE:\n",
    "        for i in question_samples[0]:\n",
    "            filename = data_unlabeled.filenames[i]\n",
    "            print (filename)\n",
    "            print ('**************************content***************************')\n",
    "            print (data_unlabeled.data[i])\n",
    "            print ('**************************content end***********************')\n",
    "            print (\"Annotate this text (select one label):\")\n",
    "            for i in range(0, len(categories)):\n",
    "                print (\"%d = %s\" %(i+1, categories[i]))\n",
    "            labelNumber = input(\"Enter the correct label number:\")\n",
    "            while labelNumber.isdigit()== False:\n",
    "                labelNumber = input(\"Enter the correct label number (a number please):\")\n",
    "            labelNumber = int(labelNumber)\n",
    "            category = categories[labelNumber - 1] \n",
    "            dstDir = os.path.join(TRAIN_FOLDER, category) \n",
    "            shutil.move(filename, dstDir)\n",
    "            \n",
    "        #shuffle train and test sets\n",
    "            \n",
    "            dstDir = os.path.join(\"./all_clac\") \n",
    "            srcDir = os.path.join(\"./train/clac/\")\n",
    "            # selectionner les fichiers texte à déplacer\n",
    "            files = [f for f in glob.glob(srcDir + \"/*.txt\", recursive=True)]\n",
    "\n",
    "            #for f in files:\n",
    "             #   print(f)\n",
    "            \n",
    "            for f in files:\n",
    "                shutil.move(f, dstDir)\n",
    "                \n",
    "            dstDir = os.path.join(\"./all_clac\") \n",
    "            srcDir2 = os.path.join(\"./test/clac\")\n",
    "\n",
    "            files = [f for f in glob.glob(srcDir2 + \"/*.txt\", recursive=True)]\n",
    "\n",
    "            #for f in files:\n",
    "             #   print(f)\n",
    "\n",
    "            for f in files:\n",
    "                shutil.move(f, dstDir)\n",
    "            \n",
    "            dstDir = os.path.join(\"./all_pas_clac\") \n",
    "            srcDir = os.path.join(\"./train/pas_clac/\")\n",
    "\n",
    "            files = [f for f in glob.glob(srcDir + \"/*.txt\", recursive=True)]\n",
    "\n",
    "            #for f in files:\n",
    "            #    print(f)\n",
    "\n",
    "            for f in files:\n",
    "                shutil.move(f, dstDir)\n",
    "    \n",
    "            dstDir = os.path.join(\"./all_pas_clac\") \n",
    "            srcDir2 = os.path.join(\"./test/pas_clac\")\n",
    "\n",
    "            files = [f for f in glob.glob(srcDir2 + \"/*.txt\", recursive=True)]\n",
    "\n",
    "            #for f in files:\n",
    "            #     print(f)\n",
    "\n",
    "            for f in files:\n",
    "                shutil.move(f, dstDir)\n",
    "            \n",
    "            srcDir_all_clac = os.path.join(\"./all_clac\")\n",
    "            srcDir_all_pas_clac = os.path.join(\"./all_pas_clac\")\n",
    "\n",
    "            # To count samples in each class\n",
    "            no_clac = len(os.listdir(srcDir_all_clac))\n",
    "            print(\"Nombre de complications liées au cathéterisme :\")\n",
    "            print(no_clac)\n",
    "\n",
    "            no_pas_clac = len(os.listdir(srcDir_all_pas_clac))\n",
    "            print(\"Nombre d'exemples qui ne sont pas des complications liées au cathéterisme :\")\n",
    "            print(no_pas_clac)\n",
    "\n",
    "            no_total = len( (os.listdir(srcDir_all_clac)) + (os.listdir(srcDir_all_pas_clac)) )\n",
    "            print(\"Total :\")  \n",
    "            print(no_total)\n",
    "            \n",
    "            s_test_clac = int(no_clac * 0.3)\n",
    "            print(\"Nombre d'exemples de clac pour le test set :\")\n",
    "            print(s_test_clac)\n",
    "\n",
    "            s_test_pas_clac = int(no_pas_clac * 0.3)\n",
    "            print(\"Nombre d'exemples de pas clac pour le test set :\")\n",
    "            print(s_test_pas_clac)\n",
    "\n",
    "            s_train_clac = no_clac - s_test_clac\n",
    "            print(\"Nombre d'exemples de clac pour le train set :\")\n",
    "            print(s_train_clac)\n",
    "\n",
    "            s_train_pas_clac = no_pas_clac - s_test_pas_clac\n",
    "            print(\"Nombre d'exemples de pas clac pour le train set :\")\n",
    "            print(s_train_pas_clac)\n",
    "            \n",
    "            s_train = s_train_clac + s_train_pas_clac\n",
    "            print(\"Nombre d'exemples pour le train set :\")\n",
    "            print(s_train)\n",
    "\n",
    "            s_test = s_test_clac + s_test_pas_clac\n",
    "            print(\"Nombre d'exemples pour le test set :\")\n",
    "            print(s_test)\n",
    "        \n",
    "            def move(srcDir, dstDir, share=None):\n",
    "                files = [f for f in glob.glob(srcDir + \"/*.txt\", recursive=True)]\n",
    "                if share is None:\n",
    "                    share =  len(files)\n",
    "                for f in random.sample(files, share):\n",
    "                    shutil.move(f, dstDir)\n",
    "                    \n",
    "            # test_clac\n",
    "\n",
    "            srcDir = os.path.join(\"./all_clac\")\n",
    "            dstDir = os.path.join(\"./test/clac\")\n",
    "            share = s_test_clac\n",
    "\n",
    "            move(srcDir, dstDir, share)\n",
    "            \n",
    "            # train_clac\n",
    "\n",
    "            srcDir = os.path.join(\"./all_clac\")\n",
    "            dstDir = os.path.join(\"./train/clac\")\n",
    "            share = (s_train_clac - 1)\n",
    "            move(srcDir, dstDir, share)\n",
    "\n",
    "\n",
    "            # test_pas_clac\n",
    "\n",
    "            srcDir = os.path.join(\"./all_pas_clac\")\n",
    "            dstDir = os.path.join(\"./test/pas_clac\")\n",
    "            share = s_test_pas_clac\n",
    "\n",
    "            move(srcDir, dstDir, share)\n",
    "            \n",
    "            # train_pas_clac\n",
    "\n",
    "            srcDir = os.path.join(\"./all_pas_clac\")\n",
    "            dstDir = os.path.join(\"./train/pas_clac\")\n",
    "            share = (s_train_pas_clac - 1)\n",
    "            move(srcDir, dstDir, share)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        break                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Classify unlabeled samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## In our case, we do not classify unlabeled samples with SVM model but with FLAIR Text \n",
    "# Classifier.\n",
    "all_labels = results[0][0].predict(X_unlabeled)\n",
    "for it in range(len(all_labels)):\n",
    "    \n",
    "    lab = all_labels[it]\n",
    "    filename = data_unlabeled.filenames[it]\n",
    "    \n",
    "    category = categories[lab - 1]\n",
    "    dstDir = os.path.join(TRAIN_FOLDER, category) \n",
    "    shutil.move(filename, dstDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Create DEV and TRAIN datasets for FLAIR Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To group samples and make with 30% of them a DEV set and 70% of them a TRAIN set\n",
    "# tu train FLAIR Text Classifier.\n",
    "# We will evaluate classifier performances on a TEST set labelled at random (i.e. without\n",
    "# active learning)\n",
    "\n",
    "# Files with major adverse event samples\n",
    "path_clac1 = 'train/clac'\n",
    "path_clac2 = 'test/clac'\n",
    "\n",
    "ext = '.txt' # Select your file delimiter\n",
    "\n",
    "file_dict = {} # Create an empty dict\n",
    "\n",
    "# Select only files with the ext extension\n",
    "txt_files_1 = [i for i in os.listdir(path_clac1) if os.path.splitext(i)[1] == ext]\n",
    "txt_files_2 = [i for i in os.listdir(path_clac2) if os.path.splitext(i)[1] == ext]\n",
    "\n",
    "# to check samples number\n",
    "print(len(txt_files_1))\n",
    "print(len(txt_files_2))\n",
    "\n",
    "print('********************************************')\n",
    "\n",
    "# Iterate over your txt files\n",
    "for f in txt_files_1:\n",
    "    # Open them and assign them to file_dict\n",
    "    with open(os.path.join(path_clac1,f)) as file_object:\n",
    "        file_dict[f] = file_object.read()\n",
    "        \n",
    "for f in txt_files_2:\n",
    "    # Open them and assign them to file_dict\n",
    "    with open(os.path.join(path_clac2,f)) as file_object:\n",
    "        file_dict[f] = file_object.read()\n",
    "        \n",
    "# Iterate over your dict and print the key/val pairs.\n",
    "for i in file_dict:\n",
    "    print (i, file_dict[i])\n",
    "    \n",
    "# Create a dataframe from this dict\n",
    "df = pd.DataFrame.from_dict(file_dict, orient='index')\n",
    "\n",
    "# Add label 1\n",
    "df['label'] = \"1\"\n",
    "\n",
    "# reset index et nommer les colonnes\n",
    "df = df.reset_index()\n",
    "df.columns = [\"index\", \"exemple\", \"label\"]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('touteslesclacs.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files with NON major adverse event samples\n",
    "path_clac1 = 'train/pas_clac'\n",
    "path_clac2 = 'test/pas_clac'\n",
    "\n",
    "ext = '.txt' # Select your file delimiter\n",
    "\n",
    "file_dict = {} # Create an empty dict\n",
    "\n",
    "# Select only files with the ext extension\n",
    "txt_files_1 = [i for i in os.listdir(path_clac1) if os.path.splitext(i)[1] == ext]\n",
    "txt_files_2 = [i for i in os.listdir(path_clac2) if os.path.splitext(i)[1] == ext]\n",
    "\n",
    "# check\n",
    "print(len(txt_files_1))\n",
    "print(len(txt_files_2))\n",
    "print('********************************************')\n",
    "\n",
    "# Iterate over your txt files\n",
    "for f in txt_files_1:\n",
    "    # Open them and assign them to file_dict\n",
    "    with open(os.path.join(path_clac1,f)) as file_object:\n",
    "        file_dict[f] = file_object.read()\n",
    "        \n",
    "for f in txt_files_2:\n",
    "    # Open them and assign them to file_dict\n",
    "    with open(os.path.join(path_clac2,f)) as file_object:\n",
    "        file_dict[f] = file_object.read()\n",
    "        \n",
    "# Iterate over your dict and print the key/val pairs.\n",
    "for i in file_dict:\n",
    "    print (i, file_dict[i])\n",
    "    \n",
    "# Create a dataframe from this dict\n",
    "df = pd.DataFrame.from_dict(file_dict, orient='index')\n",
    "\n",
    "# Add label 0\n",
    "df['label'] = \"0\"\n",
    "\n",
    "# reset index et nommer les colonnes\n",
    "df = df.reset_index()\n",
    "df.columns = [\"index\", \"exemple\", \"label\"]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('touteslespasclacs.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat every annotated samples (positives or not)\n",
    "# and then split DEV and TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clac = pd.read_csv('touteslesclacs.csv', sep=';', encoding='utf-8')\n",
    "pas_clac = pd.read_csv('touteslespasclacs.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "clac = clac[['index', 'exemple', 'label']]\n",
    "pas_clac = pas_clac[['index', 'exemple', 'label']]\n",
    "\n",
    "exemples_annotes = pd.concat([clac, pas_clac])\n",
    "\n",
    "train, test = train_test_split(exemples_annotes, test_size=0.3)\n",
    "\n",
    "print(train)\n",
    "\n",
    "print('*****************************************')\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('dev.csv', sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
